# Robot Perception by Agreement

## Overview
This project explores how a robot’s level of agreement with human opinions influences its perceived friendliness, intelligence, and autonomy. Using the NAO robot, we developed three interaction models:
1. **Agreement Model** – The robot agrees with the user.
2. **Neutral Model** – The robot remains objective.
3. **Disagreement Model** – The robot challenges the user's opinions.

## Research Objective
The study investigates whether a robot that agrees with a user is perceived as friendlier and how neutrality or disagreement affects perceptions of intelligence and autonomy.

## Methodology
For this project, the NAO robot is used, incorporating verbal and non-verbal cues to interact with users. Each participant engages with one of the three models and then completes an interview to assess their perception of the robot.
  
## Project Structure
- `mainForAgree.py` - Script for the agreement model  
- `mainForNeutral.py` - Script for the neutral model  
- `mainForDisagree.py` - Script for the disagreement model  
- `non_verbal_cues.py` - Defines robot gestures and lighting cues  
- `Topics.py` - Predefined discussion topics and robot responses  

## Results
Findings suggest:
- Agreement enhances perceived friendliness but may reduce autonomy.  
- Disagreement promotes engagement but can feel frustrating.  
- Neutrality appears logical but lacks warmth and emotional connection.  

## Contributors
- Kacper Nizielski  
- Alejandro Lopez  
- Emmanouil Zagoritis  
